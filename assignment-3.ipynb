{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 3\n",
    "In this assignment you will be working with an accelerometer dataset recoreded when participants in a study where executing some task, for example, jogging. Our task is to predict the activity of a participant given the accelerometer data. This is known as the activity recognition task.\n",
    "\n",
    "The data is gathered from a laboratory experiment which is described in more detail [here](http://www.cis.fordham.edu/wisdm/dataset.php) and published in the paper \"Activity Recognition using Cell Phone Accelerometers\" (Kwapisz et al. 2010).\n",
    "\n",
    "Your task in this assignment is to train a neural network predicts the activity being performed. You can use what ever network architecture you want to. In order to pass this assignment you will need to achieve accuracy higher than 80%, for a higher score you will need to achieve accuracy higher than 90%.\n",
    "\n",
    "In order to make the assignment easier we provide you with the data preprocessing code so you only need to implement the model. As a starting point, try these layers when testing architectures.\n",
    "- `layer_dense`\n",
    "- `layer_conv_1d`\n",
    "- `layer_gru`\n",
    "\n",
    "In order to achieve accuracy higher than 90% you might need to preprocess the data differently. We leave that up to you. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we start by loading the required libraries. In the `assignment-3-helpers.R` you will find the function `create_sequences_x_y <- function(data, sequence_length, target_shift, step_shift)` which we used to generate the sequences. You will also find the function `load_activity_dataset <- function()` to load the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(keras)\n",
    "library(ggplot2)\n",
    "source(\"assignment-3-helpers.R\")\n",
    "\n",
    "set_thread_count(2L)\n",
    "# This specifies the number of threads TensorFlow will use. You can change this number, \n",
    "# but it depends on the model, what the optimal number of threads might be.\n",
    "# In my experiments 2 threads performed quite well for simpleRNNs.\n",
    "# Using more than 2 threads increased communication overhead between CPUs and decreased the training speed.\n",
    "# To change this value simply set the value which you want and then -\n",
    "# click \"Kernel\" -> \"Shutdown\" and then \"Kernel\" -> \"Restart\".\n",
    "# If you do not shutdown the kernel, the change will not take effect."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Prepare the data\n",
    "In this assignment we will do the usual preprocessing steps, read the data, split and scale the data. You will not have to do much in this part but we recommend reading it through as you might want to adjust it later.\n",
    "\n",
    "## 1.1 Read data\n",
    "In the cell below we load the dataset by calling the function `load_activity_dataset()`. This will download the data into the folder `data/WISDM_ar_v1.1` and return the contents of the file `data/WISDM_ar_v1.1/WISDM_ar_v1.1_raw_cleaned.txt`. We also reccomend reading the `data/WISDM_ar_v1.1/readme.txt` file supplied by the researchers with the dataset.\n",
    "\n",
    "We save the data as `data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data <- load_activity_dataset()\n",
    "dim(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset contains 6 columns. The following description is adjust from the file `data/WISDM_ar_v1.1/WISDM_ar_v1.1_raw_about.txt`.\n",
    "- UserId: nominal, 1..36. A unique identifier per study participant.\n",
    "- Activity: nominal, {Walking, Jogging, Sitting, Standing, Upstairs, Downstairs }. The task which the participant is performing during the measurement. We want to predict this value.\n",
    "- Timestamp: numeric, generally the phone's uptime in nanoseconds.\n",
    "- x-acceleration: numeric, floating-point values between -20 .. 20. The acceleration in the x direction as measured by the android phone's accelerometer. A value of 10 = 1g = 9.81 m/s^2, and 0 = no acceleration. The acceleration recorded includes gravitational acceleration toward the center of the Earth, so that when the phone is at rest on a flat surface the vertical axis will register +-10.\n",
    "- y-accel: numeric, see x-acceleration\n",
    "- z-accel: numeric, see x-acceleration\n",
    "\n",
    "A datapoint is collected every 50 ms, or at 20Hz. We want to create sequences which last roughly 5 seconds, which means that we will need to have a sequence length of 100 using this sample rate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will not use the \"Timestamp\" column, so let us drop it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data <- data[, -(3)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Some data exploration\n",
    "The histogran plot below shows that the activity distribution is not balanced. Walking and jogging are by far the most common activities. We will need to take this into account when splitting the dataset into train/val/test as we want each dataset to have the same distribution of activities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(ggplot2)\n",
    "ggplot(data, aes(x=Activity)) +\n",
    "  geom_bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us also plot the number of examples we have for each user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(ggplot2)\n",
    "ggplot(data, aes(x=UserId)) +\n",
    "  geom_bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Dataset splitting\n",
    "We want to create a neural network model which can correctly recognise the activity of a new user. We will therefore evaluate the model on users we do not train on. We will therefore need to sample users to use for our training, validation and test sets.\n",
    "\n",
    "We will do this manually and check the class distribution in of each dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We select users from 24 up to and including 30 to be in our validation data.\n",
    "val_idx <- data['UserId'] == '24' |\n",
    "             data['UserId'] == '25' |\n",
    "             data['UserId'] == '26' |\n",
    "             data['UserId'] == '27' |\n",
    "             data['UserId'] == '28' |\n",
    "             data['UserId'] == '29' |\n",
    "             data['UserId'] == '30'\n",
    "val_data <- data[val_idx, ]\n",
    "# The fraction of the total data\n",
    "nrow(val_data)/nrow(data)\n",
    "ggplot(val_data, aes(x=Activity)) +\n",
    "  geom_bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distribution is not exactly the same as we saw over the whole data. We seem to be lacking some \"Sitting\" examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_idx <- data['UserId'] == '31' |\n",
    "              data['UserId'] == '32' |\n",
    "              data['UserId'] == '33' |\n",
    "              data['UserId'] == '34' |\n",
    "              data['UserId'] == '35' |\n",
    "              data['UserId'] == '36'\n",
    "test_data <- data[test_idx, ]\n",
    "nrow(test_data)/nrow(data)\n",
    "ggplot(test_data, aes(x=Activity)) +\n",
    "  geom_bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our test dataset seems to have a similar distribution as our whole dataset, and in the cell below we will see that our training set is very similar to our test set. We thus expect our model to generalise well from the training data to the test data and we expect to perform better on the test set rather than the validation set. This means that our validation dataset will be harder than the test dataset. Keep this in mind when training and evaluating your model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our training dataset will be the remaining rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we select all entities in the validation set and the test set, and take the compliment.\n",
    "train_idx <- !(val_idx | test_idx)\n",
    "train_data <- data[train_idx, ]\n",
    "nrow(train_data)/nrow(data)\n",
    "ggplot(train_data, aes(x=Activity)) +\n",
    "  geom_bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we drop the `UserId` column as we will not use it to make predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data <- train_data[, -(1)]\n",
    "val_data <- val_data[, -(1)]\n",
    "test_data <- test_data[, -(1)]\n",
    "dim(train_data)\n",
    "dim(val_data)\n",
    "dim(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Creating sequences\n",
    "Now we want to create the sequences which we will use to train and evaluate our model. Our sequences will be 5 seconds long, that is, a sequence length of 100. We use the label of the last element in the sequence as a target, `target_shift = -1`. Since our dataset is quite large we get plenty of examples, so we shift 50 steps for each sequence to keep the number of sequences in an acceptable range (this sequence length and shift was set after some experimentation). Feel free to adjust these values if you feel like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_seq <- create_sequences_x_y(data = train_data, sequence_length = 100, target_shift = -1, step_shift = 50)\n",
    "dim(train_seq$x)\n",
    "dim(train_seq$y)\n",
    "val_seq <- create_sequences_x_y(data = val_data, sequence_length = 100, target_shift = -1, step_shift = 50)\n",
    "dim(val_seq$x)\n",
    "dim(val_seq$y)\n",
    "test_seq <- create_sequences_x_y(data = test_data, sequence_length = 100, target_shift = -1, step_shift = 50)\n",
    "dim(test_seq$x)\n",
    "dim(test_seq$y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A minor note: When creating the sequences we created some sequences which contain data from two different UserIds, which will never happen in real-life. We do not care that much about this defect in our data processing, since the number of sequences which are from two different UserIds are **very** few (at most 36*2 out of 14132+3832+3995)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we drop last few columns which we do not need. We drop the label from the input sequences and drop the accelormeter data from the targets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep drop labels for the input features, x\n",
    "train_seq$x <- train_seq$x[ , , -1]\n",
    "# Keep the labels for the y data.\n",
    "train_seq$y <- train_seq$y[ , 1]\n",
    "head(train_seq$x)\n",
    "head(train_seq$y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We do the same for the validation and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_seq$x <- val_seq$x[ , , -1]\n",
    "val_seq$y <- val_seq$y[ , 1]\n",
    "test_seq$x <- test_seq$x[ , , -1]\n",
    "test_seq$y <- test_seq$y[ , 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 Scaling\n",
    "To help our network train faster, we need to **scale** our data. In this assignment we will scale our data using the Min/Max approach, the same approach as we did for for the last assignment.\n",
    "\n",
    "We will scale the data so that the largest value in our training data will have value `1` and the smallest value will have the value `0`. To achieve this we do:\n",
    "\n",
    "$$\n",
    "x' = \\frac{x - \\min(\\boldsymbol{x})}{\\max(\\boldsymbol{x}) - \\min(\\boldsymbol{x})}\n",
    "$$\n",
    "\n",
    "Where $x$ is a single example and $x'$ is our new scaled value. $\\min(\\boldsymbol{x})$ is the smallest value in the training set and $\\max(\\boldsymbol{x})$ is the largest value.\n",
    "For the interested we recommend the [wikipedia article](https://en.wikipedia.org/wiki/Feature_scaling)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We initialise our arrays in the shape we want them to be.\n",
    "x_train_scaled <- array(0, dim = dim(train_seq$x))\n",
    "x_val_scaled <- array(0, dim = dim(val_seq$x))\n",
    "x_test_scaled <- array(0, dim = dim(test_seq$x))\n",
    "dim(x_train_scaled)\n",
    "dim(x_val_scaled)\n",
    "dim(x_test_scaled)\n",
    "\n",
    "\n",
    "for (j in 1:dim(train_seq$x)[3]) {\n",
    "    # For each feature we compute the max and scale\n",
    "    min_train <- min(as.numeric(train_seq$x[,,j]))\n",
    "    max_train <- max(as.numeric(train_seq$x[,,j]))\n",
    "    \n",
    "    # For each dataset and feature we scale the values according to the max/min\n",
    "    x_train_scaled[,,j] <- (as.numeric(train_seq$x[,,j]) - min_train) / (max_train - min_train)\n",
    "    x_val_scaled[,,j] <- (as.numeric(val_seq$x[,,j]) - min_train) / (max_train - min_train)\n",
    "    x_test_scaled[,,j] <- (as.numeric(test_seq$x[,,j]) - min_train) / (max_train - min_train)\n",
    "}\n",
    "min(x_train_scaled)\n",
    "max(x_train_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need to map our labels to the one-hot encoding representation, as a first step we need to map the text to a numerical value and then we use the `to_categorical` function from Keras. The `category_to_label` function below maps the text to a numerical value which the `to_categorical` function can translate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_to_label <- function(category) {\n",
    "    if (category == \"Downstairs\")\n",
    "        0\n",
    "    else if (category == \"Jogging\")\n",
    "        1\n",
    "    else if (category == \"Sitting\")\n",
    "        2\n",
    "    else if (category == \"Standing\")\n",
    "        3\n",
    "    else if (category == \"Upstairs\")\n",
    "        4\n",
    "    else if (category == \"Walking\")\n",
    "        5\n",
    "    else\n",
    "        -1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train <- to_categorical(lapply(train_seq$y, FUN = category_to_label))\n",
    "y_val <- to_categorical(lapply(val_seq$y, FUN = category_to_label))\n",
    "y_test <- to_categorical(lapply(test_seq$y, FUN = category_to_label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. The model\n",
    "In this section you will implement the model. You need to construct a model which assigns one of 6 classes to each sequence.\n",
    "\n",
    "To achieve a score of `1` for the assignment you only need to implement the baseline model and achieve accuracy higher than 80% on the **test set**. To achieve a score of `2` for the assignment you will need to achieve accuracy higher than 90% on the **test set**. Keep in mind that the test set is easier than the validation set.\n",
    "\n",
    "We leave the model definition completely up to you but suggest that you start by trying some of the layers below.\n",
    "- `layer_dense`\n",
    "- `layer_conv_1d`\n",
    "- `layer_gru`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you finished tuning your model evaluate your model and report the loss over the test set. Methodologically, you should only evaluate your once (or not very often). Try to keep to that convention."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the model\n",
    "Evaluate your model and report the loss over the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model %>% evaluate(x_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
