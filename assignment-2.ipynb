{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2\n",
    "\n",
    "The dataset we will be using in this assignment is the sunspots dataset made available by [SILSO](http://sidc.be/silso/home), Sunspot Index and Long-term Solar Observations, by the Royal Observatory in Belgium. The dataset is shared under the [CC BY-NC 4.0](https://creativecommons.org/licenses/by-nc/4.0/) license. We have made no changes to the original dataset but you only work with a few columns of the data.\n",
    "\n",
    "The dataset consists of the monthly mean number of sunspots on the sun, dating back to January 1749.\n",
    "Our goal in this assignment is to make a time-series model to predict the number of sunspots next month.\n",
    "The structure of the assignment is very similar to the 05a notebook, it consists of the following steps.\n",
    "\n",
    "1. Read dataset and make a simple plot.\n",
    "1. Create training and testing sequences.\n",
    "1. Split the dataset into train/test.\n",
    "1. Scale the dataset using the min/max approach (unlike 05a notebook).\n",
    "1. Create an RNN which uses a single recurrent layer (SimpleRNN, GRU or LSTM) and then a regression layer.\n",
    "1. Predict the monthly mean number of sunspots for April 2019.\n",
    "\n",
    "Doing all of these steps sufficiently well in addition to getting low enough loss, will give you a score of 1. At this stage you are not allowed to change the sequence length used to train and test. All other hyperparameters are up to you, including the loss function.\n",
    "\n",
    "To receive a score of 2 you will need to do further improvements to your model. You will need to achieve a lower test score **and** apply **two** (or more) of the following techniques.\n",
    "1. Make the RNN stateful.\n",
    "1. Apply (input/recurrect/normal) dropout.\n",
    "1. Add dense layers after the recurrent layer.\n",
    "1. Stack multiple RNNs.\n",
    "1. Adjust the sequence length."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we start by loading the required libraries. In the `assignment-2-helpers.R` you will find the following functions `split_dataset <- function(x_data, y_data, fraction = 0.2)` which we used in the 05a notebook to split our dataset into train/test datasets. You will also find the function `create_sequences_x_y <- function(data, sequence_length, target_shift, step_shift)` which we used to generate the sequences. Lastly, you will find the function `load_sunspots_dataset <- function()` to load the dataset.\n",
    "\n",
    "The `create_sequences_x_y` and `split_dataset` are optional functions and you can use them, but you do not need to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(keras)\n",
    "library(ggplot2)\n",
    "source(\"assignment-2-helpers.R\")\n",
    "\n",
    "use_multi_cpu(2L)\n",
    "# This specifies the number of threads TensorFlow will use. You can change this number, \n",
    "# but it depends on the model, what the optimal number of threads might be.\n",
    "# In my experiments 2 threads performed quite well for simpleRNNs.\n",
    "# Using more than 2 threads increased communication overhead between CPUs and decreased the training speed.\n",
    "# To change this value simply set the value which you want and then -\n",
    "# click \"Kernel\" -> \"Shutdown\" and then \"Kernel\" -> \"Restart\".\n",
    "# If you do not shutdown the kernel, the change will not take effect."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Read data and plot\n",
    "## 1.1 Read data\n",
    "In the cell below load the dataset by calling the function `load_sunspots_dataset()`. Explore the columns and check the dimensions of the dataset. What are the dimensions of the dataset? It is sufficient to print the number out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Plot the data\n",
    "In the cell below plot the `Mean monthly sunspots`. You can use the plot function you want to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Find the cycle\n",
    "From the plot we want to see how many timesteps it takes for the cyclic pattern to repeate it self. From the plot how many timesteps, circa, does each cycle have? Write your answer in the cell below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Creating sequences\n",
    "Now we want to create the sequences which we will then use to train and test our model. We will not use all features of the data to create the sequences, but only the monthly mean number of sunspots.\n",
    "## 2.1 Eliminate all extra features from the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Create sequences\n",
    "Given the monthly mean number of sunspots create sequences with sequence length of 100. Feel free to use the `create_sequences_x_y` function.\n",
    "\n",
    "For each sequence, the target value should be the next month's monthly mean number of sunspots. That is, if the last element in our sequence is the sunspot number for March 2019, we want our target to be number of sunspots for April 2019 (the value for April 2019 is not in the data but March 2019 is). If you change the sequence length, do not change the `target_shift` (if you use `create_sequences_x_y`).\n",
    "\n",
    "The `step_shift` is up to you.\n",
    "\n",
    "This is a sequence length is very close to the observed cycles in the data. We leave it up to you to experiment with different sequence lengths for extra points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Splitting\n",
    "Now we must split our dataset into train/test. Feel free to use the `split_dataset` function for this. Remember that the function returns a list containing `x_train`, `y_train`, `x_test` and `y_test`.\n",
    "## 3.1 Split to train/test\n",
    "Split the dataset into train/test. Make sure that test set contains sequences which are **after** the training set. The test set should contain 20% of the sequences from the whole dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Scaling\n",
    "To help our network train faster, we need to **scale** our data. In this assignment we will scale our data using the Min/Max approach, the same approach as we did for pixel values. \n",
    "\n",
    "We will not use the **normalisation** approach since we do not expect our data to be normally distributed. Up to this point we have not been precise in class and called both approaches \"scaling\" when in fact **normalisation** is scaling by the mean and standard deviation and assumes that our data is normally distributed. This is not the case now and we will scale the data so that the largest value in our training data will have value `1` and the smallest value will have the value `0`. To achieve this we do:\n",
    "\n",
    "$$\n",
    "x' = \\frac{x - \\min(\\boldsymbol{x})}{\\max(\\boldsymbol{x}) - \\min(\\boldsymbol{x})}\n",
    "$$\n",
    "\n",
    "Where $x$ is a single example and $x'$ is our new scaled value. $\\min(\\boldsymbol{x})$ is the smallest value in the training set and $\\max(\\boldsymbol{x})$ is the largest value.\n",
    "For the interested we recommend the [wikipedia article](https://en.wikipedia.org/wiki/Feature_scaling)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Calculate the max and min\n",
    "Calculate the max and min of the monthly mean sunspots over the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Scale the training and test data\n",
    "Scale the training and test data using the Min/Max scaling approach defined above. Your implementation of the scaling approach does not have to look like the formula above but it needs to have the same effect. Do not scale the targets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. The baseline model\n",
    "In this section you will implement a baseline timeseries model. To achieve a score of `1` for the assignment you only need to implement the baseline model and achieve the following test scores.\n",
    "- Using \"mae\" loss you need to have test loss lower than `30`\n",
    "- Using \"mse\" loss you need to have test loss lower than `2000`\n",
    "\n",
    "You should use a Simple RNN, GRU or an LSTM layer in your model and after that layer you should implement a regression layer. Besides these requirements we leave the rest of the model definition and hyperparameter selection up to you.\n",
    "\n",
    "## 5.1 Baseline model\n",
    "Implement a model based on the description above.\n",
    "\n",
    "**Hint** To speed up training it is helpful to remove the `callbacks=list(Progress$new())` line from the `fit` function. The side-effect is that you have less idea of how far in the training process you are, but you can be sure that it is about 1/5 faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you finished tuning your model evaluate your model and report the loss over the test set. Methodologically, you should only evaluate your once (or not very often). Try to keep to that convention."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Evaluate the model\n",
    "Evaluate your model and report the loss over the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 Predict the monthly mean number of sunspots for April 2019\n",
    "Now we will use our baseline model to predict the monthly mean number of sunpots for April 2019. This requires you to use the `predict` function exposed by Keras. We used this function in notebook 05a.\n",
    "\n",
    "You will need to manually create the correct sequence. The sequence will need to have the same sequence length as we used to train the model. To feed it to the network it will need to have dimensions `(1, 100, 1)`, to achieve this create and array like this: `array(your_sequence, dim = c(1, 100, 1))`. This will correctly shape the data when you have extracted the correct sequence, `your_sequence`.\n",
    "\n",
    "**Hint** It is probably best to go all the way back to the cleaned data from excercise 2.1 and create the sequence from there. Do not forget to scale it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6 Improving the model\n",
    "Below you can try to improve the model you created in section 5.\n",
    "Feel free to add cells by clicking \"Insert -> Insert Cell Below/Above\".\n",
    "\n",
    "To get a score of `2` for this assignment you will need to\n",
    "- get \"mae\" loss below `18` or \n",
    "- get \"mse\" loss below `600` on the test set\n",
    "\n",
    "**and do two** of the following.\n",
    "1. Make the RNN stateful.\n",
    "1. Apply (input/recurrect/normal) dropout.\n",
    "1. Add dense layers after the recurrent layer.\n",
    "1. Stack multiple GRUs.\n",
    "1. Adjust the sequence length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
